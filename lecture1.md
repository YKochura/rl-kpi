class: middle, center, title-slide

# –ù–∞–≤—á–∞–Ω–Ω—è –∑ –ø—ñ–¥–∫—Ä—ñ–ø–ª–µ–Ω–Ω—è–º

–õ–µ–∫—Ü—ñ—è 1: –í—Å—Ç—É–ø

<br><br>
–ö–æ—á—É—Ä–∞ –Æ—Ä—ñ–π –ü–µ—Ç—Ä–æ–≤–∏—á<br>
[iuriy.kochura@gmail.com](mailto:iuriy.kochura@gmail.com) <br>
<a href="https://t.me/y_kochura">@y_kochura</a> <br>


---

# –°—å–æ–≥–æ–¥–Ω—ñ

- –û–≥–ª—è–¥ –æ—Å–Ω–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è
- –ü–æ–±—É–¥–æ–≤–∞ –Ω–µ–π—Ä–æ–Ω–Ω–∏—Ö –º–µ—Ä–µ–∂

---

class: middle

# –û–≥–ª—è–¥ –æ—Å–Ω–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è

## –©–æ —Ç–∞–∫–µ –º–∞—à–∏–Ω–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è?

---

class: middle

# –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∑–∞ –ê—Ä—Ç—É—Ä –°–µ–º—é–µ–ª—å

.center[
.width-100[![](figures/lec1/def1.png)]
]

---

class: middle

# –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∑–∞ –¢–æ–º –ú—ñ—Ç—á–µ–ª–ª


–¢–æ–º –ú—ñ—Ç—á–µ–ª–ª (1998): –ö–æ–º–ø‚Äô—é—Ç–µ—Ä–Ω–∞ –ø—Ä–æ–≥—Ä–∞–º–∞, —è–∫–∞ —É—á–∏—Ç—å—Å—è –∑ –¥–æ—Å–≤i–¥—É **E** –ø–æ –≤i–¥–Ω–æ—à–µ–Ω–Ω—é –¥–æ –¥–µ—è–∫–æ–≥–æ
–∫–ª–∞—Å—É –∑–∞–¥–∞—á **T** —Ç–∞ –ºi—Ä–∏ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Çi **P** –Ω–∞–∑–∏–≤–∞—î—Ç—å—Å—è –º–∞—à–∏–Ω–Ω–∏–º –Ω–∞–≤—á–∞–Ω–Ω—è–º, —è–∫—â–æ —ó—ó –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ωi—Å—Ç—å —É –∑–∞–¥–∞—á–∞—Ö
–∑ **T**, —â–æ –≤–∏–ºi—Ä—é—î—Ç—å—Å—è –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é **P**, –ø–æ–∫—Ä–∞—â—É—î—Ç—å—Å—è –∑ –¥–æ—Å–≤i–¥–æ–º **E**.

.right[
.width-30[![](figures/lec1/tm.png)]
]

  - –î–æ—Å–≤—ñ–¥ (–¥–∞–Ω—ñ): —ñ–≥—Ä–∏ –≤ —è–∫—ñ –≥—Ä–∞—î –ø—Ä–æ–≥—Ä–∞–º–∞ —Å–∞–º–∞ –∑ —Å–æ–±–æ—é
  - –í–∏–º—ñ—Ä –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ: –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –≤–∏–≥—Ä–∞—à—É

---


class: middle

# –ö–ª–∞—Å–∏—á–Ω–µ –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω vs –º–∞—à–∏–Ω–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è

.center[
.width-100[![](figures/lec1/mlVSprograming1.png)]
]

---


class: middle
count: false

# –ö–ª–∞—Å–∏—á–Ω–µ –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω vs –º–∞—à–∏–Ω–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è

.center[
.width-100[![](figures/lec1/mlVSprograming.png)]
]

---

class: middle

# –¢–∏–ø–∏ –Ω–∞–≤—á–∞–Ω–Ω—è

–ó–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–æ–º –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö (**–¥–æ—Å–≤i–¥—É**) –º–∞—à–∏–Ω–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è –ø–æ–¥i–ª—è—é—Ç—å –Ω–∞ —á–æ—Ç–∏—Ä–∏ —Ç–∏–ø–∏: –∫–æ–Ω—Ç—Ä–æ–ª—å–æ–≤–∞–Ω–µ (–∑ —É—á–∏—Ç–µ–ª–µ–º), –Ω–∞–øi–≤–∫–æ–Ω—Ç—Ä–æ–ª—å–æ–≤–∞–Ω–µ, –Ω–µ–∫–æ–Ω—Ç—Ä–æ–ª—å–æ–≤–∞–Ω–µ (–±–µ–∑ —É—á–∏—Ç–µ–ª—è) —Ç–∞ –∑ –øi–¥–∫—Äi–ø–ª–µ–Ω–Ω—è–º.

.center[
.width-100[![](figures/lec1/types1.png)]
]

---

class: middle
count: false

# –¢–∏–ø–∏ –Ω–∞–≤—á–∞–Ω–Ω—è

.center[
.width-100[![](figures/lec1/types2.png)]
]

---

class: middle
count: false

# –¢–∏–ø–∏ –Ω–∞–≤—á–∞–Ω–Ω—è

.center[
.width-100[![](figures/lec1/types3.png)]
]

---

class: middle
count: false

# –¢–∏–ø–∏ –Ω–∞–≤—á–∞–Ω–Ω—è

.center[
.width-100[![](figures/lec1/types4.png)]
]

---

class: middle

# –Ø–∫ –≤—á–∏—Ç—å—Å—è –ª—é–¥–∏–Ω–∞?

- –ú–∏ —Ç–∞ —ñ–Ω—à—ñ —Ä–æ–∑—É–º–Ω—ñ —ñ—Å—Ç–æ—Ç–∏, –≤—á–∏–º–æ—Å—å –∑–∞–≤–¥—è–∫–∏ **–≤–∑–∞—î–º–æ–¥—ñ—ó —ñ–∑ —Å–≤–æ—ó–º –æ—Ç–æ—á–µ–Ω–Ω—è–º**

- –í–∑–∞—î–º–æ–¥—ñ—ó —á–∞—Å—Ç–æ –±—É–≤–∞—é—Ç—å **–ø–æ—Å–ª—ñ–¥–æ–≤–Ω–∏–º–∏** - –º–∞–π–±—É—Ç–Ω—ñ –≤–∑–∞—î–º–æ–¥—ñ—ó –º–æ–∂—É—Ç—å –∑–∞–ª–µ–∂–∞—Ç–∏ –≤—ñ–¥ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ—Ö

- –ú–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω—ñ –Ω–∞ **—Ä–µ–∑—É–ª—å—Ç–∞—Ç**

- –ú–∏ –º–æ–∂–µ–º–æ –≤—á–∏—Ç–∏—Å—è **–Ω–µ –º–∞—é—á–∏ –ø—Ä–∏–∫–ª–∞–¥—ñ–≤** –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ—ó –ø–æ–≤–µ–¥—ñ–Ω–∫–∏

---

class: middle

# –ú–æ–∑–æ–∫ –ª—é–¥–∏–Ω–∏

–ë–∞–∑–æ–≤–æ—é –æ–±—á–∏—Å–ª—é–≤–∞–ª—å–Ω–æ—é –æ–¥–∏–Ω–∏—Ü–µ—é –º–æ–∑–∫—É —î –Ω–µ–π—Ä–æ–Ω. –ú–æ–∑–æ–∫ –¥–æ—Ä–æ—Å–ª–æ—ó –ª—é–¥–∏–Ω–∏ —Å–∫–ª–∞–¥–∞—î—Ç—å—Å—è –∑ $86$ –ºi–ª—å—è—Ä–¥i–≤ –Ω–µ–π—Ä–æ–Ωi–≤, —è–∫i –∑‚Äô—î–¥–Ω–∞–Ωi –º—ñ–∂ —Å–æ–±–æ—é –ø—Ä–∏–±–ª–∏–∑–Ω–æ
$10^{14}$ ‚àí $10^{15}$ —Å–∏–Ω–∞–ø—Å–∞–º–∏.

.footnote[–î–∂–µ—Ä–µ–ª–æ: [F. A. Azevedo —Ç–∞ —ñ–Ω.](https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.21974), 2009.]

---

class: middle

# –ë—ñ–æ–ª–æ–≥—ñ—á–Ω–∏–π —Ç–∞ —à—Ç—É—á–Ω–∏–π –Ω–µ–π—Ä–æ–Ω

.center[
.width-100[![](figures/lec1/NeuronBioMathModels.png)]
]

---

class: middle,
# –î–µ—è–∫—ñ —Ñ—É–Ω–∫—Ü—ñ—ó –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó

.center[
.width-100[![](figures/lec1/actFunctions.png)]
]

---


class: middle

# –õ—é–¥–∏–Ω–∞ –¥–æ–±—Ä–µ —Å–ø—Ä–∏–π–º–∞—Ç–∏ –≤—ñ–∑—É–∞–ª—å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é

---

class: middle, center

.width-100[![](figures/lec1/mushrooms.png)]

–©–æ –í–∏ –±–∞—á–∏—Ç–µ?

???

.italic[–Ø–∫ –í–∏ —Ü–µ —Ä–æ–±–∏—Ç–µ?]

---

class: middle

.center[
.width-70[![](figures/lec1/dog1.jpg)]

–°–æ–±–∞–∫–∞-–≤—ñ–≤—Ü—è —á–∏ —à–≤–∞–±—Ä–∞?
]


---


class: middle

–õ—é–¥—Å—å–∫–∏–π –º–æ–∑–æ–∫ –Ω–∞—Å—Ç—ñ–ª—å–∫–∏ –¥–æ–±—Ä–µ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É—î –≤—ñ–∑—É–∞–ª—å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é, —â–æ **—Ä–æ–∑—Ä–∏–≤** –º—ñ–∂ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º —Ç–∞ –π–æ–≥–æ —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ—é —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—î—é (–ø—ñ–∫—Å–µ–ª—è–º–∏) –≤–∞–∂–∫–æ –æ—Ü—ñ–Ω–∏—Ç–∏ —ñ–Ω—Ç—É—ó—Ç–∏–≤–Ω–æ: 

<br>
.center[
![](figures/lec1/mushroom-small.png)

–¶–µ –º—É—Ö–æ–º–æ—Ä.
]

---

class: middle, center

.width-70[![](figures/lec1/mushroom-big.png)]

–¶–µ –º—É—Ö–æ–º–æ—Ä.

---

class: middle, center

.width-30[![](figures/lec1/mushroom-rgb0.png)] +
.width-30[![](figures/lec1/mushroom-rgb1.png)] +
.width-30[![](figures/lec1/mushroom-rgb2.png)]


–¶–µ –º—É—Ö–æ–º–æ—Ä.

---

class: middle, center

.width-80[![](figures/lec1/mushroom-small-nb.png)]

–¶–µ –º—É—Ö–æ–º–æ—Ä.

---

class: middle, center

# –Ø–∫ –Ω–∞–≤—á–∏—Ç—å –º–∞—à–∏–Ω –±–∞—á–∏—Ç–∏?

---

class: middle

.center.width-60[![](figures/lec1/cat1.png)]

---

count: false
class: black-slide

.center.width-60[![](figures/lec1/cat2.png)]

---

count: false
class: black-slide, middle

.center.width-80[![](figures/lec1/cat3.png)]

---

count: false
class: black-slide, middle

.center.width-80[![](figures/lec1/cat4.png)]

---

class: middle

–î–ª—è –ø–æ—à—É–∫—É —à–∞–±–ª–æ–Ω—É –≤ –¥–∞–Ω–∏—Ö (–≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó, –æ–∑–Ω–∞–∫) –ø–æ—Ç—Ä—ñ–±–Ω–∞ –ø–æ–±—É–¥–æ–≤–∞ **—Å–∫–ª–∞–¥–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π**, —è–∫—ñ –± –æ—Ç—Ä–∏–º–∞—Ç–∏ –≤—Ä—É—á–Ω—É –±—É–ª–æ –± –¥—É–∂–µ —Å–∫–ª–∞–¥–Ω–æ.

–û–¥–Ω–∞–∫, –º–æ–∂–Ω–∞ –Ω–∞–ø–∏—Å–∞—Ç–∏ –ø—Ä–æ–≥—Ä–∞–º—É, —è–∫–∞ –±—É–¥–µ **–≤—á–∏—Ç–∏—Å—å** –∑–Ω–∞—Ö–æ–¥–∏—Ç–∏ —à–∞–±–ª–æ–Ω –≤ –¥–∞–Ω–∏—Ö —Å–∞–º–æ—Å—Ç—ñ–π–Ω–æ. 

---

class: middle

.center.width-100[![](figures/lec1/deepL.jpg)]

---

class: middle

# –©–æ –≤—Ö–æ–¥–∏—Ç—å –¥–æ –∑–∞–¥–∞—á—ñ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è?

- –ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ–±–ª–µ–º–∏ + –¥–∞–Ω—ñ
- –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
- –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ—ó –≤—Ç—Ä–∞—Ç
- –í–∏–±—ñ—Ä –∞–ª–≥–æ—Ä–∏—Ç–º—É –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó

---

class: middle

# –Ø–∫—ñ –¥–∞–Ω—ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è?

.center.width-100[![](figures/lec1/inp3.png)]

---

class: middle

# –û–∑–Ω–∞–∫–∏ —É –º–∞—à–∏–Ω–Ω–æ–º—É –Ω–∞–≤—á–∞–Ω–Ω—ñ

–û–∑–Ω–∞–∫–∏ - —Ü–µ —Å–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è, —è–∫—ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –¥–ª—è –ø—Ä–∏–π–Ω—è—Ç—Ç—è —Ä—ñ—à–µ–Ω—å –º–æ–¥–µ–ª–ª—é.

- –î–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –∑–æ–±—Ä–∞–∂–µ–Ω—å **–∫–æ–∂–µ–Ω** –ø—ñ–∫—Å–µ–ª—å —î –æ–∑–Ω–∞–∫–æ—é
- –î–ª—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –≥–æ–ª–æ—Å—É, **—á–∞—Å—Ç–æ—Ç–∞** —Ç–∞ **–≥—É—á–Ω—ñ—Å—Ç—å** —î –æ–∑–Ω–∞–∫–∞–º–∏
- –î–ª—è –±–µ–∑–ø—ñ–ª–æ—Ç–Ω–∏—Ö –∞–≤—Ç–æ–º–æ–±—ñ–ª—ñ–≤ –¥–∞–Ω—ñ –∑ **–∫–∞–º–µ—Ä**, **—Ä–∞–¥–∞—Ä—ñ–≤** —ñ **GPS** —î –æ–∑–Ω–∞–∫–∞–º–∏

---

class: middle

# –¢–∏–ø–∏ –æ–∑–Ω–∞–∫ —É —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω—ñ—Ü—ñ

- –ü—ñ–∫—Å–µ–ª—ñ (RGB –¥–∞–Ω—ñ)
- –ì–ª–∏–±–∏–Ω–∞ (—Å–æ–Ω–∞—Ä, –ª–∞–∑–µ—Ä–Ω—ñ –¥–∞–ª–µ–∫–æ–º—ñ—Ä–∏)
- –û—Ä—ñ—î–Ω—Ç–∞—Ü—ñ—è –∞–±–æ –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è (–≥—ñ—Ä–æ—Å–∫–æ–ø, –∞–∫—Å–µ–ª–µ—Ä–æ–º–µ—Ç—Ä, –∫–æ–º–ø–∞—Å)

---

class: middle

# –ù–µ–¥–æ–Ω–∞–≤—á–∞–Ω–Ω—è vs –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è

.center.width-100[![](figures/lec1/Regularization.png)]

---

class: middle
count: false

# –ù–µ–¥–æ–Ω–∞–≤—á–∞–Ω–Ω—è vs –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è

.center.width-80[![](figures/lec1/fittings.jpg)]

---


class: middle

# –©–æ —Ç–∞–∫–µ –º–æ–¥–µ–ª—å?

–•–æ—á–∞ —Ç–µ, —â–æ –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤—Å–µ—Ä–µ–¥–∏–Ωi –≥–ª–∏–±–∏–Ω–Ω–æ—ó –Ω–µ–π—Ä–æ–Ω–Ω–æ—ó –º–µ—Ä–µ–∂i, –º–æ–∂–µ –±—É—Ç–∏ —Å–∫–ª–∞–¥–Ω–∏–º, –∑–∞ —Å–≤–æ—î—é —Å—É—Ç—Ç—é —Ü–µ –ø—Ä–æ—Å—Ç–æ —Ñ—É–Ω–∫—Üi—ó. –í–æ–Ω–∏ –±–µ—Ä—É—Ç—å –ø–µ–≤–Ωi –≤—Öi–¥–Ωi –¥–∞–Ωi: **INPUT x** i
–≥–µ–Ω–µ—Ä—É—é—Ç—å –¥–µ—è–∫i –≤–∏—Öi–¥–Ωi –¥–∞–Ωi: **OUTPUT f(x)**

.center.width-30[![](figures/lec1/func.png)]

---


# –ó —á–æ–≥–æ —Å–∫–ª–∞–¥–∞—î—Ç—å—Å—è –º–æ–¥–µ–ª—å?

.center.width-100[![](figures/lec1/compon.png)]

---

# –î–∂–µ—Ä–µ–ª–∞ –ø–æ–º–∏–ª–æ–∫ –º–æ–¥–µ–ª—ñ

- –ó—Å—É–≤  (Bias)
- –†–æ–∑–∫–∏–¥ (Variance)
- –®—É–º (Irreducible error)

$$Err = Bias^2 + Variance + Irreducible error$$

.center.width-70[![](figures/lec1/biasvariance.png)]

---

# –Ü–Ω—Ç—É—ó—Ü—ñ—è

<br><br>
.center.width-55[![](figures/lec1/bias-and-variance.jpg)]

---



class: middle

# –û–±–ª—Å—Ç—ñ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è —Ç–∞ —É—Å–ø—ñ—Ö–∏ –®–Ü

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/5kpsZoKjPgQ" frameborder="0" allowfullscreen></iframe>

Object detection, pose estimation, segmentation (2019)

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/V1eYniJ0Rnk" frameborder="0" allowfullscreen></iframe>

Reinforcement learning (Mnih et al, 2014)

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/HcZ48JDamyk" frameborder="0" allowfullscreen></iframe>

Strategy games (Deepmind, 2016-2018)

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/qhUvQiKec2U" frameborder="0" allowfullscreen></iframe>

Autonomous cars (NVIDIA, 2016)

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/tlThdr3O5Qo" frameborder="0" allowfullscreen></iframe>

Autopilot (Tesla, 2019)

???

A full build of Autopilot neural networks involves 48 networks that take 70,000 GPU hours to train üî•. Together, they output 1,000 distinct tensors (predictions) at each timestep.

---

class: middle, black-slide

.center[
<video loop controls preload="auto" height="400" width="600">
  <source src="./figures/lec1/physics-simulation.mp4" type="video/mp4">
</video>

Physics simulation (Sanchez-Gonzalez et al, 2020)

]

---

class: middle, black-slide, center

<iframe width="600" height="450" src="https://www.youtube.com/embed/gg7WjuFs8F4" frameborder="0" allowfullscreen></iframe>

AI for Science (Deepmind, AlphaFold, 2020)

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/7gh6_U7Nfjs" frameborder="0" allowfullscreen></iframe>

Speech synthesis and question answering (Google, 2018)

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/Khuj4ASldmU" frameborder="0" allowfullscreen></iframe>

Artistic style transfer (Ruder et al, 2016)

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/kSLJriaOumA" frameborder="0" allowfullscreen></iframe>

Image generation (Karras et al, 2018)

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/egJ0PTKQp4U?start=223" frameborder="0" allowfullscreen></iframe>

Music composition (NVIDIA, 2017)

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/BIDaxl4xqJ4" frameborder="0" allowfullscreen></iframe>

Dali Lives (2019)

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/J_2fIGmsoRg" frameborder="0" allowfullscreen></iframe>

Reface –æ–∂–∏–≤–∏–≤ –≤—ñ–¥–æ–º—ñ –∫–∏—ó–≤—Å—å–∫—ñ –º—É—Ä–∞–ª–∏ –¥–æ –î–Ω—è –ö–∏—î–≤–∞ (2021)

---

class: middle, center

.width-70[![](figures/lec1/turing-award.png)]

.italic[ –ê—Å–æ—Ü—ñ–∞—Ü—ñ—î—é –æ–±—á–∏—Å–ª—é–≤–∞–ª—å–Ω–æ—ó —Ç–µ—Ö–Ω—ñ–∫–∏ (ACM) –Ω–∞–≥–æ—Ä–æ–¥–∂–µ–Ω–æ –≤ 2018 —Ä–æ—Ü—ñ –ø—Ä–µ–º—ñ—î—é –¢—é—Ä—ñ–Ω–≥–∞ —Ç–∞–∫–∏—Ö –Ω–∞—É–∫–æ–≤—Ü—ñ–≤: .bold[Yann LeCun], .bold[Geoffrey Hinton], .bold[Yoshua Bengio]  –∑–∞ –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ñ —Ç–∞ —ñ–Ω–∂–µ–Ω–µ—Ä–Ω—ñ –ø—Ä–æ—Ä–∏–≤–∏, —è–∫—ñ –∑—Ä–æ–±–ª–∏ –≤ –≥–ª–∏–±–∏–Ω–Ω–∏—Ö –Ω–µ–π—Ä–æ–Ω–Ω–∏—Ö –º–µ—Ä–µ–∂–∞—Ö.]

---

# –ß–æ–º—É DL –ø—Ä–∞—Ü—é—î?

.center.grid[
.kol-1-2[
–ê–ª–≥–æ—Ä–∏—Ç–º–∏ (—Å—Ç–∞—Ä—ñ —Ç–∞ –Ω–æ–≤—ñ)<br><br>
.width-90[![](figures/lec1/skip-connection.png)]
]
.center.kol-1-2[
–ó—Ä–æ—Å—Ç–∞—î –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö<br><br>
.width-50[![](figures/lec1/imagenet.jpeg)]
]
]

.center.grid[
.kol-1-2[
–ü—Ä–æ–≥—Ä–∞–º–Ω–µ –∑–∞–±–µ–∑–ø–µ—á–µ–Ω–Ω—è<br>
.width-90[![](figures/lec1/software.png)]
]
.kol-1-2[
–ë—ñ–ª—å—à —à–≤–∏–¥–∫—ñ –æ–±—á–∏—Å–ª—é–≤–∞–ª—å–Ω—ñ –º–∞—à–∏–Ω–∏ <br><br>
.width-50[![](figures/lec1/titan.jpg)]
]
]

???

–£—Å–ø—ñ—Ö –≥–ª–∏–±–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è —î –±–∞–≥–∞—Ç–æ—Ñ–∞–∫—Ç–æ—Ä–Ω–∏–º ...

---



class: middle

.center.circle.width-30[![](figures/lec1/bishop.jpg)]

.italic["For the last forty years we have programmed computers; for the next forty years we will train them."]

.pull-right[Chris Bishop, 2020.]

???
–ö—Ä—ñ—Å—Ç–æ—Ñ–µ—Ä –ë—ñ—à–æ–ø —î —Ç–µ—Ö–Ω—ñ—á–Ω–∏–º —Å–ø—ñ–≤—Ä–æ–±—ñ—Ç–Ω–∏–∫–æ–º Microsoft —ñ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º Microsoft Research AI4Science. –í—ñ–Ω —Ç–∞–∫–æ–∂ —î –ø–æ—á–µ—Å–Ω–∏–º –ø—Ä–æ—Ñ–µ—Å–æ—Ä–æ–º –∫–æ–º–ø‚Äô—é—Ç–µ—Ä–Ω–∏—Ö –Ω–∞—É–∫ –ï–¥–∏–Ω–±—É—Ä–∑—å–∫–æ–≥–æ —É–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç—É —Ç–∞ —á–ª–µ–Ω–æ–º –î–∞—Ä–≤—ñ–Ω—ñ–≤—Å—å–∫–æ–≥–æ –∫–æ–ª–µ–¥–∂—É –≤ –ö–µ–º–±—Ä–∏–¥–∂—ñ. –£ 2017 —Ä–æ—Ü—ñ –≤—ñ–Ω –±—É–≤ –æ–±—Ä–∞–Ω–∏–π —á–ª–µ–Ω–æ–º –ö–æ—Ä–æ–ª—ñ–≤—Å—å–∫–æ–≥–æ —Ç–æ–≤–∞—Ä–∏—Å—Ç–≤–∞.

---

class: middle

# –í–∏–∫–ª–∏–∫–∏ –®–Ü


–û—Å–Ω–æ–≤–Ω–∏–º –≤–∏–∫–ª–∏–∫–æ–º —à—Ç—É—á–Ω–æ–≥–æ —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É —Ç–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è —î –ø—Ä–∏–π–Ω—è—Ç—Ç—è –ø—Ä–∞–≤–∏–ª—å–Ω–∏—Ö —Ä—ñ—à–µ–Ω—å –≤ —É–º–æ–≤–∞—Ö **–Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–æ—Å—Ç—ñ**

---

class: blue-slide, middle, center
count: false

.larger-xx[–ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω]

–û–¥–Ω–æ—à–∞—Ä–æ–≤–∞ –Ω–µ–π—Ä–æ–Ω–Ω–∞ –º–µ—Ä–µ–∂–∞

–ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω vs –õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è

---

# –ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω

–ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω (Rosenblatt, 1958)

$$g(z) = \begin{cases}
   1 &\text{if } z =\sum_i w_i x_i + b \geq 0  \\\\
   0 &\text{otherwise}
\end{cases}$$

–¶—è –º–æ–¥–µ–ª—å —Å–ø–æ—á–∞—Ç–∫—É –±—É–ª–∞ –º–æ—Ç–∏–≤–æ–≤–∞–Ω–∞ –±—ñ–æ–ª–æ–≥—ñ—î—é, –¥–µ $w_i$ &mdash; —Ü–µ —Å–∏–Ω–∞–ø—Ç–∏—á–Ω—ñ –≤–∞–≥–∏ –¥–ª—è –≤—Ö—ñ–¥–Ω–∏—Ö —Å–∏–≥–Ω–∞–ª—ñ–≤ $x_i$ —Ç–∞  $g$ –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó.
.center.width-65[![](figures/lec1/perceptron.jpg)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: Frank Rosenblatt, [Mark I Perceptron operators' manual](https://apps.dtic.mil/sti/pdfs/AD0236965.pdf), 1960.]

???

–£ –ª–∏—Å—Ç–æ–ø–∞–¥—ñ 1958 —Ä–æ–∫—É –§—Ä–µ–Ω–∫ –†–æ–∑–µ–Ω–±–ª–∞—Ç—Ç –≤–∏–Ω–∞–π—à–æ–≤ –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω, –∞–±–æ Mark I, —É –ö–æ—Ä–Ω–µ–ª—å—Å—å–∫–æ–º—É —É–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç—ñ. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–π —É 1960 —Ä–æ—Ü—ñ, —Ü–µ –±—É–≤ –ø–µ—Ä—à–∏–π –∫–æ–º–ø‚Äô—é—Ç–µ—Ä, —è–∫–∏–π –º—ñ–≥ –≤–∏–≤—á–∞—Ç–∏ –Ω–æ–≤—ñ –Ω–∞–≤–∏—á–∫–∏ –º–µ—Ç–æ–¥–æ–º –ø—Ä–æ–± —ñ –ø–æ–º–∏–ª–æ–∫, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ —Ç–∏–ø –Ω–µ–π—Ä–æ–Ω–Ω–æ—ó –º–µ—Ä–µ–∂—ñ, —è–∫–∞ —Å–∏–º—É–ª—é–≤–∞–ª–∞ –ø—Ä–æ—Ü–µ—Å–∏ –º–∏—Å–ª–µ–Ω–Ω—è –ª—é–¥–∏–Ω–∏.

---

class: middle

.center[
.width-70[![](figures/lec1/neuron.png)]
]

.smaller-xx[
$$
\begin{aligned}
\mathbf{X} = \begin{bmatrix}
x\_1  \\\\
x\_2  \\\\
\vdots \\\\
x\_m
\end{bmatrix} 
&&
\mathbf{W} = \begin{bmatrix}
w\_1  \\\\
w\_2  \\\\
\vdots \\\\
w\_m
\end{bmatrix}
&& 
\mathbf{X}^T = \begin{bmatrix}
x\_1 & x\_2 & \cdots & x\_m
\end{bmatrix} 
\end{aligned}$$


$$\boxed{\begin{aligned}z &= \sum\_{n=1}^{m} w\_n x\_n + b = \mathbf{X}^T \cdot \mathbf{W} + b = \mathbf{W}^T \cdot \mathbf{X} + b \\\\
\hat y &= g(z) \\\\
\mathcal{L}(\hat y, y) &= - \frac{1}{n} \sum\_{i=1}^{n} \big(y^{(i)} \log(\hat y^{(i)}) + (1- y^{(i)}) \log(1 -\hat y^{(i)}) \big)
\end{aligned}}$$

]

---

class: middle

.center[
.width-80[![](figures/lec1/neuron.png)]
]

.smaller-xx[

.center[*–ü—Ä—è–º–µ –ø–æ—à–∏—Ä–µ–Ω–Ω—è*]

$$\boxed{\begin{aligned}z &= \sum\_{n=1}^{m} w\_n x\_n + b = \mathbf{X}^T \cdot \mathbf{W} + b = \mathbf{W}^T \cdot \mathbf{X} + b \\\\
\hat y &= g(z) \\\\
\mathcal{L}(\hat y, y) &= - \frac{1}{n} \sum\_{i=1}^{n} \big(y^{(i)} \log(\hat y^{(i)}) + (1- y^{(i)}) \log(1 -\hat y^{(i)}) \big)
\end{aligned}}$$

]

---


class: middle

## –ü—Ä–∏–∫–ª–∞–¥

–ü—Ä–∏–ø—É—Å—Ç–∏–º–æ $m = 3$

$$
\begin{aligned}
\mathbf{X} = \begin{bmatrix}
x\_1  \\\\
x\_2  \\\\
x\_3
\end{bmatrix} = \begin{bmatrix}
-0.1  \\\\
0.7  \\\\
0.5
\end{bmatrix} 
&&
\mathbf{W} = \begin{bmatrix}
w\_1  \\\\
w\_2  \\\\
w\_3
\end{bmatrix} =
\begin{bmatrix}
1  \\\\
-2  \\\\
2
\end{bmatrix}
&&
b = 0.8
\end{aligned}$$

$$\boxed{\begin{aligned}
z = \sum_{n=1}^{3} w_n x_n + b &= w_1 x_1 + w_2 x_2 + w_3 x_3 + b = \\\\
&= 1 \cdot -0.1 + -2 \cdot 0.7 + 2 \cdot 0.5 + 0.8 = 0.3
\end{aligned}}$$

$$\boxed{\begin{aligned}
z = \mathbf{X}^T \cdot \mathbf{W} + b &= \begin{bmatrix}
x\_1 & x\_2 &  x\_3 
\end{bmatrix} \begin{bmatrix}
w\_1  \\\\
w\_2  \\\\
w\_3
\end{bmatrix} + b = \\\\
&= w_1 x_1 + w_2 x_2 + w_3 x_3 + b = 0.3
\end{aligned}}$$

$$\hat y  = g(z) = g(\mathbf{X}^T \cdot \mathbf{W} + b) = \frac{1}{1 + \exp(-z)} = \frac{1}{1 + \exp(-0.3)} \approx 0.57 $$

---


class: blue-slide, middle, center
count: false

.larger-xx[–û–¥–Ω–æ–≤–∏–º—ñ—Ä–Ω–∏–π –≥—Ä–∞–¥—ñ—î–Ω—Ç–Ω–∏–π —Å–ø—É—Å–∫]

---


class: middle

## –û–¥–Ω–æ–≤–∏–º—ñ—Ä–Ω–∏–π –≥—Ä–∞–¥—ñ—î–Ω—Ç–Ω–∏–π —Å–ø—É—Å–∫
.smaller-x[

–†–æ–∑–≥–ª—è–Ω–µ–º–æ –¥–µ—è–∫—É –Ω–µ–ø–µ—Ä–µ—Ä–≤–Ω—É, –¥–∏—Ñ–µ—Ä–µ–Ω—Ü—ñ–π–æ–≤–∞–Ω—É  —Ñ—É–Ω–∫—Ü—ñ—é $f: \mathbb{R} \rightarrow \mathbb{R}$. –†–æ–∑–∫–ª–∞–≤—à–∏ –≤ —Ä—è–¥ –¢–µ–π–ª–æ—Ä–∞, –º–∏ –æ—Ç—Ä–∏–º—É—î–º–æ:

$$f(x + \varepsilon) = f(x) + \varepsilon f^{'}(x) + \mathcal{O}(\varepsilon^2)$$

–î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç–∏ –¥–∞–≤–∞–π—Ç–µ –≤–∏–±–µ—Ä–µ–º–æ —Ñ—ñ–∫—Å–æ–≤–∞–Ω–∏–π —Ä–æ–∑–º—ñ—Ä –∫—Ä–æ–∫—É $\alpha > 0$ —Ç–∞ –æ–±–µ—Ä–µ–º–æ $\varepsilon = -\alpha f^{'}(x)$. –ü—ñ–¥—Å—Ç–∞–≤–∏–≤—à–∏ —Ü–µ —É –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –≤–∏—Ä–∞–∑:

$$f(x -\alpha f^{'}(x)) = f(x) - \alpha f^{'2}(x)  + \mathcal{O}(\alpha^2 f^{'2}(x))$$

–Ø–∫—â–æ –ø–æ—Ö—ñ–¥–Ω–∞ $f^{'}(x) \neq 0$ –Ω–µ –∑–Ω–∏–∫–∞—î, –º–∏ —Ä–æ–±–∏–º–æ –ø—Ä–æ–≥—Ä–µ—Å, –æ—Å–∫—ñ–ª—å–∫–∏ $\alpha f^{'2}(x) > 0$. –ö—Ä—ñ–º —Ç–æ–≥–æ, –º–∏ –∑–∞–≤–∂–¥–∏ –º–æ–∂–µ–º–æ –≤–∏–±—Ä–∞—Ç–∏ $\alpha$ –¥–æ—Å–∏—Ç—å –º–∞–ª–∏–º, —â–æ–± –≤–∏—Ä–∞–∑–∏ –≤–∏—â–æ–≥–æ –ø–æ—Ä—è–¥–∫—É –∑–∞–Ω—É–ª–∏—Ç–∏. –¢–æ–º—É –º–∏ –ø—Ä–∏—Ö–æ–¥–∏–º–æ –¥–æ

$$f(x -\alpha f^{'}(x)) \lessapprox f(x)$$

–¶–µ –æ–∑–Ω–∞—á–∞—î, —â–æ —è–∫—â–æ –º–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ:

$$x \leftarrow x -\alpha f^{'}(x)$$

–¥–ª—è —ñ—Ç–µ—Ä–∞—Ü—ñ—ó –ø–æ $x$, –∑–Ω–∞—á–µ–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ—ó $f(x)$  –º–æ–∂–µ –∑–º–µ–Ω—à–∏—Ç–∏—Å—å. 
]

???
Gradient descent in one dimension is an excellent example to explain why the gradient descent algorithm may reduce the value of the objective function.

The Taylor series is used to describe what the function looks like in the neighborhood of some poin $x$.

That is, in first-order approximation $f(x + \varepsilon)$  is given by the function value $f(x)$ and the first derivative $f^{'}(x)$ at $x$. It is not unreasonable to assume that for small $\varepsilon$ moving in the direction of the negative gradient will decrease $f$. 

Therefore, in gradient descent we first choose an initial value $x$ and a constant $\alpha > 0$ and then use them to continuously iterate $x$ until the stop condition is reached, for example, when the magnitude of the gradient $|f^{'}(x)|$ is small enough or the number of iterations has reached a certain value.

---

class: middle

.center[
.width-80[![](figures/lec1/gdC.png)]
]

???

For simplicity we choose the objective function $f(x) = x^2$ to illustrate how to implement gradient descent. Although we know that $x = 0$ is the solution to minimize $f(x)$, we still use this simple function to observe how $x$ changes.

---

class: middle

–•—ñ–¥ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó –∑–∞ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏ $x$ 

.center[
.width-80[![](figures/lec1/gd025.png)]
]

---

class: middle

–•—ñ–¥ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó –∑–∞ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏ $x$ 

.center[
.width-80[![](figures/lec1/gd006.png)]
]

???
If we use a learning rate that is too small, it will cause $x$ to update very slowly, requiring more iterations to get a better solution.

---

lass: middle

–•—ñ–¥ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó –∑–∞ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏ $x$ 

.center[
.width-80[![](figures/lec1/gd1.1.png)]
]

???
if we use an excessively high learning rate, $|\alpha f^{'}(x)|$ might be too large for the first-order Taylor expansion formula. That is, the term $\mathcal{O}(\alpha^2 f^{'2}(x))$ might become significant. In this case, we cannot guarantee that the iteration of $x$ will be able to lower the value of $f(x)$.

---

class: blue-slide, middle, center
count: false

.larger-xx[–ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω: –ó–≤–æ—Ä–æ—Ç–Ω–µ –ø–æ—à–∏—Ä–µ–Ω–Ω—è]

---

class: middle

–£ –ø–æ–∑–Ω–∞—á–µ–Ω–Ω—è—Ö –õ–µ–π–±–Ω—ñ—Ü–∞ **–ø—Ä–∞–≤–∏–ª–æ –ª–∞–Ω—Ü—é–∂–∫–∞** —Å—Ç–≤–µ—Ä–¥–∂—É—î, —â–æ
$$
\begin{aligned}
\frac{\partial \ell}{\partial \theta\_i} &= \sum\_{k \in \text{parents}(\ell)} \frac{\partial \ell}{\partial u\_k} \underbrace{\frac{\partial u\_k}{\partial \theta\_i}}\_{\text{recursive case}}
\end{aligned}$$

---

class: middle

## –ó–≤–æ—Ä–æ—Ç–Ω–µ –ø–æ—à–∏—Ä–µ–Ω–Ω—è

- –û—Å–∫—ñ–ª—å–∫–∏ –Ω–µ–π—Ä–æ–Ω–Ω–∞ –º–µ—Ä–µ–∂–∞ —î **–∫–æ–º–ø–æ–∑–∏—Ü—ñ—î—é –¥–∏—Ñ–µ—Ä–µ–Ω—Ü—ñ–π–æ–≤–∞–Ω–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π**, –∑–∞–≥–∞–ª—å–Ω—ñ –ø–æ—Ö—ñ–¥–Ω—ñ –≤—Ç—Ä–∞—Ç –º–æ–∂–Ω–∞ –æ—Ü—ñ–Ω–∏—Ç–∏ –∑–≤–æ—Ä–æ—Ç–Ω–æ, –∑–∞—Å—Ç–æ—Å–æ–≤—É—é—á–∏ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–∞–≤–∏–ª–æ –ª–∞–Ω—Ü—é–∂–∫–∞ –¥–æ —ó—ó –æ–±—á–∏—Å–ª—é–≤–∞–ª—å–Ω–æ–≥–æ –≥—Ä–∞—Ñ—É.
- –†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è —Ü—ñ—î—ó –ø—Ä–æ—Ü–µ–¥—É—Ä–∏ –Ω–∞–∑–∏–≤–∞—î—Ç—å—Å—è –∑–≤–æ—Ä–æ—Ç–Ω–∏–º *–∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º –¥–∏—Ñ–µ—Ä–µ–Ω—Ü—ñ—é–≤–∞–Ω–Ω—è–º* –∞–±–æ **–∑–≤–æ—Ä–æ—Ç–Ω–∏–º –ø–æ—à–∏—Ä–µ–Ω–Ω—è–º**.

---

class: middle



.smaller-xx[

.center[*–ü—Ä—è–º–µ –ø–æ—à–∏—Ä–µ–Ω–Ω—è*]

$$\boxed{\begin{aligned}z &= \sum\_{n=1}^{m} w\_n x\_n + b = \mathbf{X}^T \cdot \mathbf{W} + b = \mathbf{W}^T \cdot \mathbf{X} + b \\\\
\hat y &= g(z) = \sigma(z) = \frac{1}{1 + \exp(-z)} \\\\
\mathcal{L}(\hat y, y) &= - \frac{1}{n} \sum\_{i=1}^{n} \big(y^{(i)} \log(\hat y^{(i)}) + (1- y^{(i)}) \log(1 -\hat y^{(i)}) \big)
\end{aligned}}$$


.grid[
.kol-2-3[

.center[*–ó–≤–æ—Ä–æ—Ç–Ω–µ –ø–æ—à–∏—Ä–µ–Ω–Ω—è*]

$$\boxed{\begin{aligned}
\frac{\partial \mathcal{L}(\hat y, y)}{\partial \hat y} &= -\frac{y}{\hat y} + \frac{1- y}{1 - \hat y} \\\\[18pt]
\frac{\partial \mathcal{L}(\hat y, y)}{\partial z} &= \frac{\partial \mathcal{L}(\hat y, y)}{\partial \hat y} \frac{\partial \hat y}{\partial z} = \hat y - y \\\\[18pt]
\frac{\partial \mathcal{L}(\hat y, y)}{\partial \mathbf{W}} &= \frac{\partial \mathcal{L}(\hat y, y)}{\partial \hat y} \frac{\partial \hat y}{\partial z} \frac{\partial z}{\partial \mathbf{W}} = \mathbf{X}^T \cdot (\hat y - y) \\\\[18pt]
\frac{\partial \mathcal{L}(\hat y, y)}{\partial b} &=  \frac{\partial \mathcal{L}(\hat y, y)}{\partial \hat y} \frac{\partial \hat y}{\partial z} \frac{\partial z}{\partial b} = \hat y - y
\end{aligned}}$$
]

.kol-1-3[
.center[*–û–Ω–æ–≤–ª–µ–Ω–Ω—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤*]

$$\boxed{\begin{aligned}
\mathbf{W} &= \mathbf{W} - \alpha \frac{\partial \mathcal{L}(\hat y, y)}{\partial \mathbf{W}} \\\\[18pt]
b &= b - \alpha \frac{\partial \mathcal{L}(\hat y, y)}{\partial b}
\end{aligned}}$$
]]
]

---

class: blue-slide, middle, center
count: false

.larger-xx[–ü–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω –∑ –±–∞–≥–∞—Ç—å–º–∞ –≤–∏—Ö–æ–¥–∞–º–∏]

---

class: middle

# Multi Output Perceptron

.smaller-x[–û—Å–∫—ñ–ª—å–∫–∏ –≤—Å—ñ –≤—Ö–æ–¥–∏ —â—ñ–ª—å–Ω–æ –∑‚Äô—î–¥–Ω–∞–Ω—ñ –∑ —É—Å—ñ–º–∞ –≤–∏—Ö–æ–¥–∞–º–∏, —Ü—ñ —à–∞—Ä–∏ –Ω–∞–∑–∏–≤–∞—é—Ç—å—Å—è *Dense*]

.center[
.width-70[![](figures/lec1/multiOuptup.png)]
]

$$z\_j = \sum\_{n=1}^{m} w\_{j, n} x\_n  + b\_j$$

---

class: middle

## Example

.center[
.width-50[![](figures/lec1/multiOuptup.png)]
]
.smaller-xx[
$$\begin{aligned}
\mathbf{X}^{m \times 1} = \begin{bmatrix}
x\_1  \\\\
x\_2  \\\\
\vdots \\\\
x\_m
\end{bmatrix} 
&&
\mathbf{W}^{3 \times m} = \begin{bmatrix}
w\_{11} & w\_{12} &  \cdots & w\_{1m} \\\\
w\_{21} & w\_{22} & \cdots & w\_{2m} \\\\
w\_{31} & w\_{32} & \cdots & w\_{3m}
\end{bmatrix}
&& 
\mathbf{b}^{3 \times 1} = \begin{bmatrix}
b\_1 \\\\
b\_2 \\\\
b\_3
\end{bmatrix}
\end{aligned}$$

$$\boxed{\begin{aligned}
\mathbf{z} =  \mathbf{W} \cdot \mathbf{X} + \mathbf{b} 
&= \begin{bmatrix}
w\_{11} & w\_{12} &  \cdots & w\_{1m} \\\\
w\_{21} & w\_{22} & \cdots & w\_{2m} \\\\
w\_{31} & w\_{32} & \cdots & w\_{3m}
\end{bmatrix} \cdot
\begin{bmatrix}
x\_1  \\\\
x\_2  \\\\
\vdots \\\\
x\_m
\end{bmatrix} + 
\begin{bmatrix}
b\_1 \\\\
b\_2 \\\\
b\_3
\end{bmatrix} = \\\\
&= 
\begin{bmatrix}
w\_{11} x\_1 + w\_{12} x\_2 +  \cdots + w\_{1m} x\_m + b\_1 \\\\
w\_{21} x\_1 + w\_{22} x\_2 +  \cdots + w\_{2m} x\_m + b\_2 \\\\
w\_{31} x\_1 + w\_{32} x\_2 +  \cdots + w\_{3m} x\_m + b\_3 
\end{bmatrix} = \begin{bmatrix}
z\_1 \\\\
z\_2 \\\\
z\_3
\end{bmatrix}
\end{aligned}}$$

]

---


class: middle

.center[
.width-100[![](figures/lec1/dense.png)]
]

.footnote[Slide source: [MIT 6.S191](http://introtodeeplearning.com/)]

---

class: middle

.smaller-x[–û—Å–∫—ñ–ª—å–∫–∏ –≤—Å—ñ –≤—Ö–æ–¥–∏ —â—ñ–ª—å–Ω–æ –∑‚Äô—î–¥–Ω–∞–Ω—ñ –∑ —É—Å—ñ–º–∞ –≤–∏—Ö–æ–¥–∞–º–∏, —Ü—ñ —à–∞—Ä–∏ –Ω–∞–∑–∏–≤–∞—é—Ç—å—Å—è *Dense*]

.center[
.width-100[![](figures/lec1/multiOuptupTF.png)]
]

$$z\_j = \sum\_{n=1}^{m} w\_{j, n} x\_n  + b\_j$$

---

class: blue-slide, middle, center
count: false

.larger-xx[–ë–∞–≥–∞—Ç–æ—à–∞—Ä–æ–≤–∏–π –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω]

---

class: middle

# –ë–∞–≥–∞—Ç–æ—à–∞—Ä–æ–≤–∏–π –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω

.center[
.width-100[![](figures/lec1/2layer.png)]
]

---

class: middle

# –ú–µ—Ä–µ–∂–∞ –∑ –æ–¥–Ω–∏–º –ø—Ä–∏—Ö–æ–≤–∞–Ω–∏–º —à–∞—Ä–æ–º

.center[
.width-100[![](figures/lec1/twoCode.png)]
]

---

class: middle

## –ú–µ—Ä–µ–∂–∞ –∑ –æ–¥–Ω–∏–º –ø—Ä–∏—Ö–æ–≤–∞–Ω–∏–º —à–∞—Ä–æ–º
.center[
.width-60[![](figures/lec1/2layer.png)]
]

.smaller-xx[
$$\begin{aligned}
\mathbf{X} = \begin{bmatrix}
x\_1  \\\\
x\_2  \\\\
x\_3
\end{bmatrix} 
&&
\mathbf{W}^{[1]} = \begin{bmatrix}
w\_{11} & w\_{12} &  w\_{13} \\\\
w\_{21} & w\_{22} &  w\_{23} \\\\
w\_{31} & w\_{32} &  w\_{33} \\\\
w\_{41} & w\_{42} &  w\_{43}
\end{bmatrix}
&& 
\mathbf{b}^{[1]} = \begin{bmatrix}
b\_1 \\\\
b\_2 \\\\
b\_3 \\\\
b\_4
\end{bmatrix}
&&
\mathbf{W}^{[2]} = \begin{bmatrix}
w\_{1} & w\_{2} &  w\_{3} & w\_{4} 
\end{bmatrix}
&& 
b^{[2]} = b
\end{aligned}$$


$$\boxed{\begin{aligned}
\mathbf{z}^{[1]} &= \mathbf{W}^{[1]} \cdot \mathbf{X} + \mathbf{b}^{[1]} \\\\
\mathbf{a}^{[1]} &= g^{[1]}(\mathbf{z}^{[1]}) \\\\
z^{[2]} &= \mathbf{W}^{[2]} \cdot \mathbf{a}^{[1]} + b^{[2]} \\\\
\hat y &= a^{[2]} = g^{[2]}(z^{[2]})
\end{aligned}}$$
]

---


class: middle

# –ì–ª–∏–±–∏–Ω–Ω–∞ –Ω–µ–π—Ä–æ–Ω–Ω–∞ –º–µ—Ä–µ–∂–∞

.center[
.width-100[![](figures/lec1/MLP2.png)]
]

---


class: end-slide, center
count: false

.larger-xx[–ö—ñ–Ω–µ—Ü—å]

---

count: false

# –õ—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∞

- LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. nature, 521(7553), 436-444.
